---
output: 
  md_document:
    toc: false
    variant: gfm

---
```{r set-options, echo=FALSE, cache=FALSE}
options(width = 10000)
```

# Simulation and Optimization for Fantasy Football Drafts

In this post, I'll use simulation and optimization to determine which draft strategies will result in the best lineups for fantasy football.

In fantasy football, there's a lot to consider when trying to figure out an optimal draft strategy. Top RB's have a high ceiling and the potential to score 350 points, whereas top WRs can only reach 275 points, however top WR's are usually seen as safer as they have a higher correlation of their preseason to end of season rank. Positions like DST, which have low ceiling and low pre-season correlation seem to be an obvious choice to draft very late. There's a lot of things to consider, and I haven't even mentioned other things like how you need to start a different number of each position. Simulation is a good way to estimate the effects of different strategies.




```{r include=F, eval=T , echo=F}

#echo prints R Code, eval evaluates R code, include includes R code output(plots/tables)
library(crosstalk)
library(knitr)
library(kableExtra)
library(DT)
library(webshot)
library(leaflet)
source("2-organize data.R")
source("3-optimization errors.R")
source("4-optimization optimize.R")

```

</br>
</br>

## 1. Organizing/Plotting the Data

The first thing I'll do is organize/plot the data. I'm using season projections from FantasyData.com, fantasyfootballanalytics.net, and FFToday.com because they have archived projections available. I'm using Average Draft Position (ADP) data from fantasyfootballcalculator.com which shows where players were drafted each year. For all of this, I'm using Half-PPR scoring and Yahoo defaults (1 QB, 2 RB, 2 WR, 1 TE, 1 RB/WR/TE, 1 DST, 1K). To start off I'll look at some summary stats:




```{r include=T, eval=T , echo=F, fig.width=6.5, fig.height=3,warning=FALSE}
#to compare projection rankings fairly, drop missing values
analyze<-all.data[complete.cases(all.data[,c("fantPts", "ADP_half", "fantPts_FFA", "fantPts_FDATA", "fantPts_FFTODAY")])|
                    (complete.cases(all.data[,c("fantPts", "ADP_half", "fantPts_FFA",  "fantPts_FFTODAY")])& all.data$Pos=='K')  ,] #
analyze<-analyze[analyze$Season>=2014,]
analyze<-ddply(analyze, .(Pos, Season), mutate,
               Actual.rank=rank(-fantPts,na.last = "keep" ),
               ADP.rank=rank(ADP_half,na.last = "keep" ),
               fantPts_AGG.rank=rank(-fantPts_AGG, na.last="keep"),
               fantpts_FFA.rank=rank(-fantPts_FFA, na.last = "keep"), #na.last=keep will return NA rank for missing values
               fantPts_FDATA.rank=rank(-fantPts_FDATA, na.last = "keep"), #na.last=keep will return NA rank for missing values
               fantPts_FFTODAY.rank=rank(-fantPts_FFTODAY, na.last = "keep") #na.last=keep will return NA rank for missing values
)
analyze<-analyze[order(analyze$Season, analyze$ADP.rank, decreasing = F),]
# head(analyze[analyze$Season==2018& analyze$Pos=="WR",], 15)
cors<-ddply(analyze, .(Pos), summarize,
            n=length(Actual.rank),
            ADP.rank=cor(Actual.rank,ADP.rank ),
            fantPts_AGG.rank=cor(Actual.rank, fantPts_AGG.rank), #comapring projection, not exactly fair
            fantpts_FFA.rank=cor(Actual.rank,fantpts_FFA.rank),
            fantPts_FDATA.rank=cor(Actual.rank,fantPts_FDATA.rank ),
            fantPts_FFTODAY.rank=cor(Actual.rank,fantPts_FFTODAY.rank)
            
)
# cors
ggplot(melt(cors[, !colnames(cors)=="n"], id.vars="Pos", value.name='cor',variable.name='Source'), aes(x=Pos, y=cor, fill=Source))+
  geom_bar(position="dodge", stat="identity")+
  ggtitle("Correlations to End of Season Rank,2014-2018")


```

From this chart, you can see that certain positions are easier to project. DST expectedly is very hard to rank preseason so is an obvious candidate to draft late. You can also see that the outside ranks have similar predictive accuracy to ADP.Rank. AGG.rank is just the mean of the outside ranks. This plot is a bit unfair though, because positions with a larger sample size will have their correlation unfairly inflated due to being able to rank further down into benchwarmer players. I'll reproduce the plot with the top 12 for each position:



```{r include=T, eval=T , echo=F, fig.width=6.5, fig.height=3,warning=FALSE}
analyze<-all.data[complete.cases(all.data[,c("fantPts", "ADP_half", "fantPts_FFA", "fantPts_FDATA", "fantPts_FFTODAY")])|
                    (complete.cases(all.data[,c("fantPts", "ADP_half", "fantPts_FFA",  "fantPts_FFTODAY")])& all.data$Pos=='K')  ,] #
analyze<-analyze[analyze$Season>=2014,]
analyze<-ddply(analyze, .(Pos, Season), mutate,
               Actual.rank=rank(-fantPts,na.last = "keep" ),
               ADP.rank=rank(ADP_half,na.last = "keep" ),
               fantPts_AGG.rank=rank(-fantPts_AGG, na.last="keep"),
               fantPts_FFA.rank=rank(-fantPts_FFA, na.last = "keep"), #na.last=keep will return NA rank for missing values
               fantPts_FDATA.rank=rank(-fantPts_FDATA, na.last = "keep"), #na.last=keep will return NA rank for missing values
               fantPts_FFTODAY.rank=rank(-fantPts_FFTODAY, na.last = "keep") #na.last=keep will return NA rank for missing values
)
cors<-ddply(analyze[analyze$ADP.rank<=12,], .(Pos), summarize,
            n=length(Actual.rank),
            ADP.rank=cor(Actual.rank,ADP.rank ),
            fantPts_AGG.rank=cor(Actual.rank, fantPts_AGG.rank), #comapring projection, not exactly fair
            fantPts_FFA.rank=cor(Actual.rank,fantPts_FFA.rank),
            fantPts_FDATA.rank=cor(Actual.rank,fantPts_FDATA.rank ),
            fantPts_FFTODAY.rank=cor(Actual.rank,fantPts_FFTODAY.rank)
            
)
# cors
ggplot(melt(cors[, !colnames(cors)=="n"], id.vars="Pos", value.name='cor',variable.name='Source'), aes(x=Pos, y=cor, fill=Source))+
  geom_bar(position="dodge", stat="identity")+
  ggtitle("Correlations to End of Season Rank,2014-2018, Top 12 players by Pos")

```


In addition, I'd also like to summarize the errors/variance:



```{r include=T, eval=T , echo=F, fig.width=6.5, fig.height=3,warning=FALSE}

ggplot(data=all.data[all.data$Pos%in% c("WR"),],aes(x=Error, y=paste0(Pos,fantPts_AGG.bin )) )+
  stat_density_ridges(quantile_lines = TRUE, quantiles = 2)

```

Above I show the distribution of errors for WRs, from 2008-2018. I am going to use this when I make my draft strategy. I want to know based on the projection and the Pos, how the error is distributed. Positive error means they overperformed their projection. Now that the data is prepared and summarized, I'm ready to test out a system.



</br>
</br>

## 2. Evaluating a Draft Strategy

After preparing the data and organizing estimated projections and errors, I'm ready to test out draft strategies. I want something [like this](https://fantasyfootballcalculator.com/draft-strategy/half-ppr/12-team/7-spot), which shows how a different strategy in R1-3 will affect a draft's projected points. This is meant to let you see what positions you should wait on drafting if you want to maximize your points. The thing that isn't accounted for in the above link though, is that in reality you are not trying to maximize projected points of a full draft, but rather for your eventual starting lineup, so you're trying to pick the draft that will give you the best eventual nine players.


My methodology consists of two functions: getPicks() and simSeason().

getPicks() takes in parameters like the slot you are drafting at, numRBs to draft, numWR to draft, and you can fix/exclude players or positions for each round as well. It then returns the draft which maximizes total points of all the picks, given the specified parameters and draft-position constraints. I show an example below, maximizing the points for Slot7/12 in a 15 round draft.


```{r include=T, eval=T , echo=T}

picks<-getPicks(slot="Slot7", data=all.data[all.data$Season==2019,], numTeams = 12,
                numRB=4, numWR = 5,numTE=2,numQB=2,numK=1, numDST=1)
```

```{r  include=T, eval=T , echo=F}
picks[, c("Player" ,"Pos","Team", "ADP_half", "ADP.Rank", "fantPts_AGG", "fantPts_AGG.bin","Slot" )]

```

Above I display the optimal planned-draft given my parameters. You can see how each player's ADP.Rank must be greater than or equal to the slot they are drafted at. 
</br>

The second function is simSeason() which takes in the above planned-draft from getPicks(), and using the errors from earlier, samples from the errors in the player's corresponding position/projection-bin to get a simulated score. Using this, I can then sort by simulated score to get the starting lineup from my draft. You only can put 9 players in your starting lineup and so if you have 2 amazing QBs in the simulated scores, only 1 will get into your simulated starting lineup. In addition, I also simulate the scores of the undrafted players, and I assume you are able to add the 4th-best simulated undrafted player at each position. I made this assumption because it is likely you will be lacking at 1-2 positions and so will be able to get a decent player as a pickup for those positions.

Below you can see an example using the above picks:


```{r include=T, eval=T , echo=T}
set.seed(1)
topLineup<-simSeason(picks = picks, data=all.data, numSims=1,
                     numRB = 2, numWR=2, numFLEX = 1,  numQB=1, numTE = 1, numDST = 1, numK = 1   )

```

```{r include=T, eval=T , echo=F}

topLineup[[1]][, c("Player" ,"Pos","Team", "ADP_half", "ADP.Rank", "fantPts_AGG", "fantPts_AGG.bin","Slot", "error", "Sim", "Pickup" )]

```


You can see from "error", which players over and underperformed in the sim, sampling the error from 2008-2018 data. Additionally, in the above sim you see how Tennessee DST made it into the top starting lineup as a pickup. I can now repeat simseason() many times, and so can get a mean simulated-lineup-total-score for the planned picks. I used 2000 as my simulation size as it seemed sufficient for the mean to converge.


```{r include=T, eval=T , echo=T}
topLineups<-simSeason(picks = picks, data=all.data, numSims=2000,
                      numRB = 2, numWR=2, numFLEX = 1,
                      numQB=1, numTE = 1, numDST = 1, numK = 1   )
summary(sapply(topLineups, function(x) sum(x$Sim)))

```

</br>
</br>


## 3. Parameter Optimization

Now I'm ready to test different getPicks() parameters to see how I should do my draft to get my the best mean-starting lineup. I included arguments in the getPicks() function such as onePos and outPos which can allow me to force positions in/out of rounds and experiment with strategies like "have exactly one TE in Rounds 1-2" or "exactly zero RB in Rounds 1-4", or other things. I test out several parameter combinations below for the 7th slot of a 12 team, 15 round draft.




```{r include=T, eval=T , echo=F, fig.width=6.5, fig.height=3,warning=FALSE,message=F}
strategies<-read.csv("strategies.csv")
strategies$Strategy<-paste(strategies$Strategy.ID, strategies$Constraints.Comments, sep=". ")


load("Data/all-slot-sims.Rda")
means<-ddply(all.slot.sims, .(Slot, Sim),summarize,
             mean.score=mean(Lineup.Score), 
             sd.score=sd(Lineup.Score), 
             high.score=sum(Lineup.Score>1900)/length(Lineup.Score))
means$Slot<-factor(means$Slot, levels=paste0("Slot", 1:12))
means$Sim<-as.numeric(gsub("simScores","", means$Sim))
means$Strategy<-strategies$Strategy[match(means$Sim,strategies$Strategy.ID)]
means$Strategy<-factor(means$Strategy, levels = means$Strategy[1:10])

ggplot(means[means$Slot=="Slot7", ], aes(x=Slot, y=mean.score, fill=Strategy))+
  geom_bar(stat = "identity", position = "dodge")+
  coord_cartesian(ylim=c(1675, 1775))+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
```


And there are the detailed parameters with each strategy:

```{r include=T, eval=T , echo=F, fig.width=7, fig.height=4,warning=FALSE,message=F}

strategies[,c("Strategy.ID", "numRB", "numWR", "numTE", "numQB", "numK", "numDST", "Constraints.Comments") ]

```
<!-- </div> -->
<!-- </div> -->



Based on the above, you can see how certain strategies don't really make a difference, and certain ones perform worse. For example the zero-WR strategies (6 & 7) perform about 50 points worse than the default strategy. Not taking a backup TE and QB also worsen the score.


</br>

Finally, I reproduce this for all draft slots. Below you can see the results, and how the best strategy is affected by your draft slot.


```{r include=T, eval=T , echo=F, fig.width=10, fig.height=4,warning=FALSE}

ggplot(means[means$Slot%in% paste0("Slot", 1:6),], aes(x=Slot, y=mean.score, fill=Strategy))+
  geom_bar(stat = "identity", position = "dodge")+
  coord_cartesian(ylim=c(1675, 1775))+
  theme(axis.title.x=element_blank())

ggplot(means[means$Slot%in% paste0("Slot", 7:12),], aes(x=Slot, y=mean.score, fill=Strategy))+
  geom_bar(stat = "identity", position = "dodge")+
  coord_cartesian(ylim=c(1675, 1775))+
  theme(axis.title.x=element_blank())

```

</br>

The above plots are a bit messy, but if you look closely you can see certain things that seem to make a difference. The 2nd and 3rd strategies-not taking a backup QB and not taking a backup TE have a negative effect, as the waiver wire adds apparently are not sufficient backup. In addition, for almost every slot the zero-RB (4&5) seems to perform better than zero-WR (6&7). This is especially true in the mid-late slots where it seems like the zero-WR does much worse.

This is just for Half-PPR 12 man leagues, and the results might change with different scoring but it at least is an attempt to quantitatively evaluate strategies.



</br>
</br>

## 4. Conclusion

Looking at the strategies, many of them perform similarly, finishing within 10-20 points. A couple did do worse, for example the zero-WR does considerably worse than zero-RB for people with mid-late slots in the draft, meaning you should likely take some WRs in the first few rounds. For these mid-late slots, zero-WR in R1-3 often performed 50 points worse than a zero-RB in it's mean simulated starting lineup, which is basically like drafting Derrick Henry over Melvin Gordon in R1, and so it isn't insignificant. If a league requires 3 WRs to start then this early RB strategy likely becomes even worse. Other parameter changes like taking backup TE/QBs also have a decent 10-20 point impact across draft slots.

Another takeaway is that projections have been about as accurate as ADP. People often assume analytics will automatically give them an edge, but often times public consensus or human rankings can be as accurate or more accurate than an analytical model. I wouldn't just go by a projection model or trust someone until I've seen it is proven to be useful, even if they try to make it sound complex. WRs do appear to be somewhat easier and so it might make sense to work on a model for them or find someone who has an accurate one.

Finally, there are a couple shortcomings with my method. Firstly, I am not accounting for opponent probabilistic picking i.e. the fact that you don't know exactly where a player will be picked. For simplicity I left this out. I think estimating a single draft like I did at least shows you things like the effect of going RB early and WR late, and keeps it simpler, despite the available players not being exact. Accounting for this though would be complicated as I'd have to return a set of potential drafts with getPicks() instead of a single draft, so I wanted to keep it simple for now.

The second main shortcoming I think is that the optimal strategy determined by the system will be dependent on the projections. For example, if there is a WR that is projected as hugely undervalued in the 10th round, then doing a WR early-RB late strategy will look bad because I am missing out on that value. I think this is something I should look into. Having said that, things like taking a backup QB/TE do seem like they'd be less affected by this. An interesting idea would be to create an entirely ADP-based projection model so that I can see how the optimal strategy would be regardless of projection system i.e. if there are no sleepers.

TLDR: Most strategies did similarly. It does seem that you should take a backup TE and QB. In addition, zero-WR strategy does not seem like a good move, especially if you are in the mid-late picks of the draft, so I'd try to draft at least 1 WR in the first few rounds. Other than that I haven't found any shocking secrets yet that will give me a huge edge. Thanks for reading!


